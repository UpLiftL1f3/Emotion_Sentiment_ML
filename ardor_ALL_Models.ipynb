{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "447085a5-9b28-4b81-a2d0-ec5d65d7512f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sabasiddiqi/Library/Python/3.9/lib/python/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ö†Ô∏è Skipping classical models: [Errno 2] No such file or directory: './models/logreg_model.pkl'\n",
      "‚úÖ DistilBERT loaded successfully!\n",
      "‚ö†Ô∏è Skipping RoBERTa: Repo id must be in the form 'repo_name' or 'namespace/repo_name': './models/roberta_ardor'. Use `repo_type` argument if needed.\n",
      "Running on local URL:  http://127.0.0.1:7862\n",
      "Running on public URL: https://4937448eb0f988df2f.gradio.live\n",
      "\n",
      "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://4937448eb0f988df2f.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Comparing ALL models at once\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import gradio as gr\n",
    "import numpy as np\n",
    "import joblib\n",
    "from transformers import AutoTokenizer, AutoModel, AutoModelForSequenceClassification\n",
    "\n",
    "# ======================================================\n",
    "# 1. Define MultiHeadDistilBert\n",
    "# ======================================================\n",
    "class MultiHeadDistilBert(nn.Module):\n",
    "    def __init__(self, base_name, num_labels_sent, num_labels_emot):\n",
    "        super().__init__()\n",
    "        self.encoder = AutoModel.from_pretrained(base_name)\n",
    "        hidden = 768\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "        self.classifier_sent = nn.Linear(hidden, num_labels_sent)\n",
    "        self.classifier_emot = nn.Linear(hidden, num_labels_emot)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        out = self.encoder(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        cls = out.last_hidden_state[:, 0]\n",
    "        cls = self.dropout(cls)\n",
    "        return {\n",
    "            \"logits_sent\": self.classifier_sent(cls),\n",
    "            \"logits_emot\": self.classifier_emot(cls)\n",
    "        }\n",
    "\n",
    "# ======================================================\n",
    "# 2. Load models\n",
    "# ======================================================\n",
    "models_dir = \"./models\"\n",
    "\n",
    "# --- Logistic Regression + SVM ---\n",
    "try:\n",
    "    logreg_model = joblib.load(os.path.join(models_dir, \"logreg_model.pkl\"))\n",
    "    svm_model = joblib.load(os.path.join(models_dir, \"svm_model.pkl\"))\n",
    "    vectorizer = joblib.load(os.path.join(models_dir, \"tfidf_vectorizer.pkl\"))\n",
    "    has_classical = True\n",
    "    print(\"‚úÖ Classical models loaded successfully!\")\n",
    "except Exception as e:\n",
    "    print(\"‚ö†Ô∏è Skipping classical models:\", e)\n",
    "    has_classical = False\n",
    "    logreg_model = svm_model = vectorizer = None\n",
    "\n",
    "# --- DistilBERT ---\n",
    "try:\n",
    "    distil_dir = \"./distilbert_ardor_saved\"\n",
    "    distil_tokenizer = AutoTokenizer.from_pretrained(distil_dir)\n",
    "    distil_model = MultiHeadDistilBert(\"distilbert-base-uncased\", 2, 6)\n",
    "    distil_model.load_state_dict(torch.load(f\"{distil_dir}/pytorch_model.bin\", map_location=\"cpu\"))\n",
    "    distil_model.eval()\n",
    "    has_distil = True\n",
    "    print(\"‚úÖ DistilBERT loaded successfully!\")\n",
    "except Exception as e:\n",
    "    print(\"‚ö†Ô∏è Skipping DistilBERT:\", e)\n",
    "    has_distil = False\n",
    "\n",
    "# --- RoBERTa ---\n",
    "try:\n",
    "    roberta_dir = os.path.join(models_dir, \"roberta_ardor\")\n",
    "    roberta_tokenizer = AutoTokenizer.from_pretrained(roberta_dir)\n",
    "    roberta_model = AutoModelForSequenceClassification.from_pretrained(roberta_dir)\n",
    "    roberta_model.eval()\n",
    "    has_roberta = True\n",
    "    print(\"‚úÖ RoBERTa loaded successfully!\")\n",
    "except Exception as e:\n",
    "    print(\"‚ö†Ô∏è Skipping RoBERTa:\", e)\n",
    "    has_roberta = False\n",
    "\n",
    "# ======================================================\n",
    "# 3. Label maps\n",
    "# ======================================================\n",
    "id2label_sent = {0: \"Negative\", 1: \"Positive\"}\n",
    "id2label_emot = {0: \"joy\", 1: \"sad\", 2: \"anger\", 3: \"fear\", 4: \"love\", 5: \"surprise\"}\n",
    "\n",
    "def softmax_temp(x, T=1.5):\n",
    "    return torch.nn.functional.softmax(x / T, dim=-1)\n",
    "\n",
    "# ======================================================\n",
    "# 4. Prediction helpers\n",
    "# ======================================================\n",
    "def predict_classical(model, text):\n",
    "    X = vectorizer.transform([text])\n",
    "    probs = model.predict_proba(X)[0]\n",
    "    idx = np.argmax(probs)\n",
    "    label = \"Positive\" if idx == 1 else \"Negative\"\n",
    "    conf = float(probs[idx])\n",
    "    return label, conf, None\n",
    "\n",
    "def predict_distilbert(text):\n",
    "    inputs = distil_tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True, max_length=128)\n",
    "    with torch.no_grad():\n",
    "        out = distil_model(**inputs)\n",
    "        ps = softmax_temp(out[\"logits_sent\"]).cpu().numpy()[0]\n",
    "        pe = softmax_temp(out[\"logits_emot\"]).cpu().numpy()[0]\n",
    "    sent_idx = int(np.argmax(ps))\n",
    "    sent_label = id2label_sent[sent_idx]\n",
    "    sent_conf = float(ps[sent_idx])\n",
    "    top_idx = np.argsort(-pe)[:3]\n",
    "    emotions = [(id2label_emot[i], float(pe[i])) for i in top_idx]\n",
    "    return sent_label, sent_conf, emotions\n",
    "\n",
    "def predict_roberta(text):\n",
    "    inputs = roberta_tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True, max_length=128)\n",
    "    with torch.no_grad():\n",
    "        logits = roberta_model(**inputs).logits\n",
    "        ps = softmax_temp(logits).cpu().numpy()[0]\n",
    "    idx = int(np.argmax(ps))\n",
    "    label = id2label_sent[idx]\n",
    "    conf = float(ps[idx])\n",
    "    return label, conf, None\n",
    "\n",
    "# ======================================================\n",
    "# 5. Compare all models at once\n",
    "# ======================================================\n",
    "def compare_models(text):\n",
    "    text = text.strip()\n",
    "    if not text:\n",
    "        return \"‚ö†Ô∏è Please enter some text to analyze.\"\n",
    "\n",
    "    results = []\n",
    "    # Classical models\n",
    "    if has_classical:\n",
    "        for name, model in [(\"Logistic Regression\", logreg_model), (\"SVM\", svm_model)]:\n",
    "            label, conf, _ = predict_classical(model, text)\n",
    "            results.append(f\"**{name}** ‚Üí {label} ({conf*100:.1f}%)\")\n",
    "\n",
    "    # DistilBERT\n",
    "    if has_distil:\n",
    "        label, conf, emo = predict_distilbert(text)\n",
    "        emo_str = \" | \".join([f\"{e[0]}: {e[1]:.2f}\" for e in emo])\n",
    "        results.append(f\"**DistilBERT** ‚Üí {label} ({conf*100:.1f}%)\\nTop Emotions: {emo_str}\")\n",
    "\n",
    "    # RoBERTa\n",
    "    if has_roberta:\n",
    "        label, conf, _ = predict_roberta(text)\n",
    "        results.append(f\"**RoBERTa** ‚Üí {label} ({conf*100:.1f}%)\")\n",
    "\n",
    "    if not results:\n",
    "        return \"‚ö†Ô∏è No models available. Please ensure they‚Äôre trained and saved.\"\n",
    "    \n",
    "    return \"\\n\\n\".join(results)\n",
    "\n",
    "# ======================================================\n",
    "# 6. Gradio Interface\n",
    "# ======================================================\n",
    "iface = gr.Interface(\n",
    "    fn=compare_models,\n",
    "    inputs=gr.Textbox(label=\"Enter text to analyze\", placeholder=\"Type something like: I love this movie!\"),\n",
    "    outputs=gr.Markdown(label=\"Model Comparison Results\"),\n",
    "    title=\"üé≠ The Ardor Scale ‚Äì Sentiment & Emotion Comparison\",\n",
    "    description=(\n",
    "        \"Enter a sentence to see predictions from all models:\\n\"\n",
    "        \"‚Ä¢ Logistic Regression and SVM (TF-IDF baselines)\\n\"\n",
    "        \"‚Ä¢ DistilBERT (sentiment + emotion)\\n\"\n",
    "        \"‚Ä¢ RoBERTa (advanced transformer)\"\n",
    "    ),\n",
    "    examples=[\n",
    "        [\"I absolutely love this project!\"],\n",
    "        [\"This is terrible and makes me so upset.\"],\n",
    "        [\"It‚Äôs okay, nothing special.\"],\n",
    "        [\"I'm so excited for the concert tonight!\"]\n",
    "    ],\n",
    "    allow_flagging=\"never\"\n",
    ")\n",
    "\n",
    "# ======================================================\n",
    "# 7. Launch App\n",
    "# ======================================================\n",
    "if __name__ == \"__main__\":\n",
    "    iface.launch(share=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dc06976-570a-4b9f-966e-90163cb0f1a6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
